{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNzsSIQ3jD4UeY+pgoq32a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha07d/Projects/blob/main/FakeNewsPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "About dataset:\n",
        "1.id - unique id for each news article\n",
        "---\n",
        "2.title - title of news article\n",
        "---\n",
        "3.author - author of news article\n",
        "---\n",
        "4.text - text in the article\n",
        "---\n",
        "5.label - real/fake\n",
        "---\n"
      ],
      "metadata": {
        "id": "m_6Gjor0ngmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dependencies"
      ],
      "metadata": {
        "id": "pocc8muDxl_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88ofETxPfCLt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#to make numpy arrays\n",
        "\n",
        "import pandas as pd\n",
        "#create dataframes\n",
        "\n",
        "import re\n",
        "#re - reg expression -search text in doc\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "#stopwords - words that donot add much value to the paragraph - a,an,where,what\n",
        "#need to remove such words - condence data  \n",
        "#nltk - natural language tool kit\n",
        "#text we deal with\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "#stemming - takes word - remove prefix and suffix -return root word\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidVectorizer\n",
        "# convert text to feature vectors\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#split dataset\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download stopwords from nltk library\n"
      ],
      "metadata": {
        "id": "mWdAc29P0oZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}